{
  "files": [],
  "history": [
    {
      "question": "tell me about above pipeline",
      "answer": "As an assistant for Thinkpalm Technologies Pvt. Ltd., I can provide information about the above pipeline.\n\n**Pipeline Overview:**\n\nThe pipeline appears to be a data processing and prediction pipeline that involves the following components:\n\n1. Data storage: The pipeline stores data in a root folder with subfolders for models and other artifacts.\n2. Model selection: The pipeline selects a suitable model based on the port-item segment and applies the previous month's model to the data point.\n3. Prediction: The pipeline applies the selected model to the data point to make a prediction.\n4. Database storage: The pipeline stores the predicted values in a database along with other relevant information.\n\n**Input Details:**\n\nThe input details for the prediction pipeline are as follows:\n\n* Expected input:\n\t+ Item name\n\t+ Port name\n\t+ Vessel name\n* Optional input:\n\t+ Quantity\n\t+ Quantity unit\n\t+ Vendor name\n\t+ Purchase type\n\n**Model Selection and Application:**\n\nThe pipeline selects a suitable model based on the port-item segment and applies the previous month's model to the data point. The models are stored in the `models` folder with subfolders for high-frequency and low-frequency models.\n\n**Database Storage:**\n\nThe pipeline stores the predicted values in a database along with other relevant information, including:\n\n* Vessel ID\n* Port name\n* Vendor name\n* Purchase type\n* Item unit category\n* Quantity\n* Date of prediction\n* Predicted unit price in USD\n* Model name\n\n**Endpoints:**\n\nThe pipeline has three endpoints:\n\n1. `/health`: for health check of the application\n2. `/train`: for training and evaluation\n3. `/retrain`: for model retraining\n\n**/train Endpoint:**\n\nThe `/train` endpoint involves the following steps:\n\n* Taking the whole data\n* Preprocessing the data\n* Splitting the data into strong and weak datasets\n* Cleaning the dataset\n* Training and testing split: 80% for training and 20% for testing\n* Applying the model based on the item-port segment\n* Evaluating the model and saving combined metrics: R2, RMSE, MSE\n\n**/retrain Endpoint:**\n\nThe `/retrain` endpoint involves the following steps:\n\n* Taking the data so far available from the database\n* Retraining the model on the same data\n* Saving the artifacts and model details in the local file folder\n* Using two buckets for item-port value count: greater than 10 and less than 10\n* Using two models: Ridge for small datasets and RandomForestRegressor for large datasets\n* Saving the model version in the format YearMonth folder inside the models folder\n* Saving the port segment map in the `port_segment_map.pkl` file"
    }
  ]
}